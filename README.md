# adversarial_test
This code let you test adversarial attacks for an easy to get situation.

## Testing
Here you are testing FGSM attacks for different weight. This test is done against a Fully Connected Neural Networks.

## Dataset
My school ENSTA Paris logo is compared to Institut Polytechnique de Paris logo. We train a neural networks to identify correctly each of the logo image and then we use fgsm to attack it.

This is only done on 14 images but it permit to easily understand how adversarial attacks works.
